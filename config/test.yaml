dataset:
    b_size: 1
    num_workers: 3
    pin_memory: True
    sample_rate: 44100
    win_size: 0.25
    hop_len: 0.25
    tr_b_size: 1
    tr_len: 

model:
    vqgan:
        vqvae:
            embed_dim: 16
            n_embed: 32
            in_ch: 1
            out_ch: 1 
            ch: 16
            ch_mult: [1, 1, 2, 2, 4] # downsampling factor: len(ch_mult) - 1
            strides: [2,2,8,8]
            attn_indices: [2]
            dilation_factor: 3
            dilation_depth: 3
            lr: 1e-4            
            loss: 
                feat_hp: 10
                spectral: true
                spectral_hp: 1.0
                spectral_n_fft: [2048, 1024, 512]
                spectral_hop_len: [512, 256, 128]
        disc:
            in_ch: 1
            ch: 16
            ch_mult: [1, 1, 2, 2, 4, 4, 8]
            stride: 4
            attn_indices: [2]
            disc_steps: 1
            lr: 1e-4
    transformer:
        vocab_size: 256 # size of vqvae vocab
        d_model: 256 # dimension of hidden units
        n_head: 4 # number of attention heads
        n_layer: 2 # number of encoder layers 
        max_len: 10000 # max number of elements in sequences   
        lr: 1e-4   